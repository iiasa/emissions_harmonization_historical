import sys

import pandas as pd
import pandas_indexing as pix


def extend_cdr_components_vectorized(cdr_components_dict, global_cdr_ext, baseline_year=2100):
    """
    Ultra-efficient CDR extension using pure vectorized operations.

    Eliminates all DataFrame fragmentation warnings by using bulk operations.

    FIXED: Handles MultiIndex alignment properly for regional fraction calculations.
    """
    extension_years = [col for col in global_cdr_ext.columns if isinstance(col, int | float) and col > baseline_year]

    print(f"Extension: {len(extension_years)} years ({min(extension_years)}-{max(extension_years)})")

    extended_components = {}

    for component_name, cdr_df in cdr_components_dict.items():
        print(component_name)

        # Validate inputs and find common scenarios
        validation_result = _validate_extension_inputs(cdr_df, global_cdr_ext, baseline_year)
        if not validation_result["is_valid"]:
            extended_components[component_name] = cdr_df.copy()
            continue

        # Calculate baseline ratios
        ratios = _calculate_baseline_ratios(cdr_df, global_cdr_ext, baseline_year)

        # Build extension data
        extension_data = _build_extension_data(
            extension_years,
            global_cdr_ext,
            ratios["baseline_data"],
            ratios["component_fractions"],
            ratios["regional_fractions"],
        )

        # Construct final DataFrame
        final_df = _construct_final_dataframe(cdr_df, extension_data, baseline_year)
        extended_components[component_name] = final_df

    return extended_components


def _validate_extension_inputs(cdr_df, global_cdr_ext, baseline_year):
    """Validate inputs and find common scenarios."""
    if baseline_year not in cdr_df.columns:
        print(f"  ⚠️  {baseline_year} not found, copying original")
        return {"is_valid": False}

    cdr_scenarios = set(cdr_df.index.get_level_values("scenario"))
    global_scenarios = set(global_cdr_ext.index.get_level_values("scenario"))
    common_scenarios = cdr_scenarios & global_scenarios

    if not common_scenarios:
        print("  ⚠️  No common scenarios, copying original")
        return {"is_valid": False}

    return {"is_valid": True, "common_scenarios": common_scenarios}


def _calculate_baseline_ratios(cdr_df, global_cdr_ext, baseline_year):
    """Calculate baseline ratios for component and regional fractions."""
    baseline_data = cdr_df[baseline_year]
    component_totals_2100 = baseline_data.groupby("scenario").sum()
    global_data_2100 = global_cdr_ext[baseline_year].groupby("scenario").first()
    component_fractions = (component_totals_2100 / global_data_2100).fillna(0)

    # Calculate regional fractions
    regional_fractions = baseline_data.copy()
    for scenario in baseline_data.index.get_level_values("scenario").unique():
        scenario_mask = baseline_data.index.get_level_values("scenario") == scenario
        scenario_data = baseline_data[scenario_mask]
        component_total = component_totals_2100[scenario]

        if component_total != 0:
            regional_fractions[scenario_mask] = scenario_data / component_total
        else:
            regional_fractions[scenario_mask] = 0

    regional_fractions = regional_fractions.fillna(0)

    return {
        "baseline_data": baseline_data,
        "component_fractions": component_fractions,
        "regional_fractions": regional_fractions,
    }


def _build_extension_data(
    extension_years,
    global_cdr_ext,
    baseline_data,
    component_fractions,
    regional_fractions,
):
    """Build extension data for all years."""
    extension_data_dict = {}

    for year in extension_years:
        if year in global_cdr_ext.columns:
            global_year_totals = global_cdr_ext[year].groupby("scenario").first()
            component_year_totals = global_year_totals * component_fractions

            year_values = baseline_data.copy()
            for scenario in baseline_data.index.get_level_values("scenario").unique():
                scenario_mask = baseline_data.index.get_level_values("scenario") == scenario
                if scenario in component_year_totals.index:
                    component_total_year = component_year_totals[scenario]
                    year_values[scenario_mask] = regional_fractions[scenario_mask] * component_total_year
                else:
                    year_values[scenario_mask] = 0

            extension_data_dict[year] = year_values

    return extension_data_dict


def _construct_final_dataframe(cdr_df, extension_data_dict, baseline_year):
    """Construct final DataFrame with original and extension data."""
    if extension_data_dict:
        original_years = [col for col in cdr_df.columns if isinstance(col, int | float) and col <= baseline_year]
        original_data = cdr_df[original_years]

        extension_df = pd.DataFrame(extension_data_dict, index=cdr_df.index)
        all_year_data = pd.concat([original_data, extension_df], axis=1)

        non_year_cols = [col for col in cdr_df.columns if not isinstance(col, int | float)]

        if len(non_year_cols) == 0:
            final_df = all_year_data.copy()
        else:
            final_df = pd.concat([all_year_data, cdr_df[non_year_cols]], axis=1)
    else:
        final_df = cdr_df.copy()
        print("  ⚠️  No extension data created")

    return final_df


def get_2100_compound_composition_co2(
    data_regional: pd.DataFrame, co2_total: pd.DataFrame, model: str, scen: str
) -> pd.DataFrame:
    """
    Find fractional composition of values in 2100 to allocate the residual end point emissions accordingly
    """
    # TODO: Clean this out to do only what we need
    sector_mapping = {
        "Emissions|CO2|AFOLU": [
            "Emissions|CO2|Peat Burning",
            "Emissions|CO2|Forest Burning",
            "Emissions|CO2|Grassland Burning" "Emissions|CO2|Agricultural Waste Burning",
            "Emissions|CO2|Agriculture",
        ],
        "Emissions|CO2|Energy and Industrial Processes": [
            "Emissions|CO2|Energy Sector",
            "Emissions|CO2|Industrial Sector",
            "Emissions|CO2|Solvents Production and Application",
            "Emissions|CO2|Waste",
            "Emissions|CO2|Aircraft",
            "Emissions|CO2|International Shipping",
            "Emissions|CO2|Transportation Sector",
            "Emissions|CO2|Soil Carbon Management",
            "Emissions|CO2|Biochar",
            "Emissions|CO2|Enhanced Weathering",
            "Emissions|CO2|Ocean",
            "Emissions|CO2|Other CDR",
            "Emissions|CO2|Direct Air Capture",
            "Emissions|CO2|BECCS",
            "Emissions|CO2|Residential Commercial Other",
        ],
        "Emissions|CO2|Gross Removals": [
            "Emissions|CO2|Soil Carbon Management",
            "Emissions|CO2|Biochar",
            "Emissions|CO2|Enhanced Weathering",
            "Emissions|CO2|Ocean",
            "Emissions|CO2|Other CDR",
            "Emissions|CO2|Direct Air Capture",
            "Emissions|CO2|BECCS",
        ],
        "Emissions|CO2|Gross Emissions": [
            "Emissions|CO2|Energy Sector",
            "Emissions|CO2|Industrial Sector",
            "Emissions|CO2|Solvents Production and Application",
            "Emissions|CO2|Waste",
            "Emissions|CO2|Aircraft",
            "Emissions|CO2|International Shipping",
            "Emissions|CO2|Transportation Sector",
            "Emissions|CO2|Residential Commercial Other",
        ],
    }

    data_total_fossil = data_regional.loc[pix.ismatch(variable="Emissions|CO2|Energy and Industrial Processes")]

    data_sub_fossil = []
    data_sub_cdr = []
    data_sub_fossil_em = []
    for sector in sector_mapping["Emissions|CO2|Energy and Industrial Processes"]:
        data_here = data_regional.loc[pix.ismatch(variable=sector)]
        if len(data_here.pix.unique("region")) > 1:
            if "World" in data_here.pix.unique("region"):
                data_here = data_here.loc[pix.ismatch(region="World")]
                print(data_here)
                sys.exit(4)
        elif data_here.shape[0] == 0:
            print("No data for sector:", sector)
            sys.exit(4)
        data_sub_fossil.append(data_regional.loc[pix.ismatch(variable=sector)])
        if sector in sector_mapping["Emissions|CO2|Gross Emissions"]:
            data_sub_fossil_em.append(data_regional.loc[pix.ismatch(variable=sector)])
        if sector in sector_mapping["Emissions|CO2|Gross Removals"]:
            data_sub_cdr.append(data_regional.loc[pix.ismatch(variable=sector)])
    data_fossil_sectors = pd.concat(data_sub_fossil)
    sum_fossil_sectors = data_fossil_sectors.sum(axis=0)
    data_cdr_sectors = pd.concat(data_sub_cdr)
    sum_cdr_sectors = data_cdr_sectors.sum(axis=0)
    data_f_em_sectors = pd.concat(data_sub_fossil_em)
    sum_f_em_sectors = data_f_em_sectors.sum(axis=0)
    print("Sum Fossil sectors vs total Fossil:", sum_fossil_sectors, data_total_fossil.values)
    fractions = data_fossil_sectors.values / sum_fossil_sectors
    fractions_df = pd.DataFrame(data=fractions, columns=["fractions"], index=data_fossil_sectors.index)
    fractions_cdr = data_cdr_sectors.values / sum_cdr_sectors
    fractions_df_cdr = pd.DataFrame(data=fractions_cdr, columns=["fractions"], index=data_cdr_sectors.index)
    fractions_f_em = data_f_em_sectors.values / sum_f_em_sectors
    fractions_df_f_em = pd.DataFrame(data=fractions_f_em, columns=["fractions"], index=data_f_em_sectors.index)
    return fractions_df, fractions_df_cdr, fractions_df_f_em


def add_removals_and_positive_fossil_emissions_to_historical(
    history: pd.DataFrame,
) -> pd.DataFrame:
    """
    Make gross positive and removal variables for CO2 in historical data
    """
    co2_ffi_hist = history.loc[pix.ismatch(variable="Emissions|CO2|Energy and Industrial Processes")].copy()

    # Create Gross Positive Emissions by copying AFOLU data and changing variable name
    gross_positive_hist = co2_ffi_hist.copy()
    new_index_gross = []
    for idx_tuple in gross_positive_hist.index:
        new_tuple = list(idx_tuple)
        new_tuple[3] = "Emissions|CO2|Gross Positive Emissions"  # variable is at position 3
        new_index_gross.append(tuple(new_tuple))
    gross_positive_hist.index = pd.MultiIndex.from_tuples(new_index_gross, names=gross_positive_hist.index.names)

    # Create Gross Removals as zeros with same structure as AFOLU
    gross_removals_hist = gross_positive_hist.copy()
    gross_removals_hist.iloc[:, :] = 0.0  # Set all values to zero
    new_index_removals = []
    for idx_tuple in gross_removals_hist.index:
        new_tuple = list(idx_tuple)
        new_tuple[3] = "Emissions|CO2|Gross Removals"  # variable is at position 3
        new_index_removals.append(tuple(new_tuple))
    gross_removals_hist.index = pd.MultiIndex.from_tuples(new_index_removals, names=gross_removals_hist.index.names)

    # Remove any previously added gross emissions variables and add the new ones
    history_clean = history.loc[
        ~history.index.get_level_values("variable").isin(
            ["Emissions|CO2|Gross Positive Emissions", "Emissions|CO2|Gross Removals"]
        )
    ]
    history = pd.concat([history_clean, gross_positive_hist, gross_removals_hist])
    print("✅ Added Gross Positive Emissions and Gross Removals to history dataframe")
    print(f"   History shape: {history.shape}")
    print(f"   Total variables: {len(history.pix.unique('variable'))}")

    return history
